@inproceedings{Sentiment:Aspect:Hu:2004,
	author = {Hu, Minqing and Liu, Bing},
	title = {Mining and Summarizing Customer Reviews},
	booktitle = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	series = {KDD '04},
	year = {2004},
	isbn = {1-58113-888-1},
	location = {Seattle, WA, USA},
	pages = {168--177},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/1014052.1014073},
	doi = {10.1145/1014052.1014073},
	acmid = {1014073},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {reviews, sentiment classification, summarization, text mining},
} 


@inproceedings{kuncoro-etal-2018-lstms,
	title = "{LSTM}s Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better",
	author = "Kuncoro, Adhiguna  and
	Dyer, Chris  and
	Hale, John  and
	Yogatama, Dani  and
	Clark, Stephen  and
	Blunsom, Phil",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P18-1132",
	pages = "1426--1436",
	abstract = "Language exhibits hierarchical structure, but recent work using a subject-verb agreement diagnostic argued that state-of-the-art language models, LSTMs, fail to learn long-range syntax sensitive dependencies. Using the same diagnostic, we show that, in fact, LSTMs do succeed in learning such dependencies{---}provided they have enough capacity. We then explore whether models that have access to explicit syntactic information learn agreement more effectively, and how the way in which this structural information is incorporated into the model impacts performance. We find that the mere presence of syntactic information does not improve accuracy, but when model architecture is determined by syntax, number agreement is improved. Further, we find that the choice of how syntactic structure is built affects how well number agreement is learned: top-down construction outperforms left-corner and bottom-up variants in capturing non-local structural dependencies.",
}

@inproceedings{dyer-etal-2016-recurrent,
	title = "Recurrent Neural Network Grammars",
	author = "Dyer, Chris  and
	Kuncoro, Adhiguna  and
	Ballesteros, Miguel  and
	Smith, Noah A.",
	booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
	month = jun,
	year = "2016",
	address = "San Diego, California",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/N16-1024",
	doi = "10.18653/v1/N16-1024",
	pages = "199--209",
}

@inproceedings{wang-etal-2018-target,
	title = "Target-Sensitive Memory Networks for Aspect Sentiment Classification",
	author = "Wang, Shuai  and
	Mazumder, Sahisnu  and
	Liu, Bing  and
	Zhou, Mianwei  and
	Chang, Yi",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P18-1088",
	pages = "957--967",
	abstract = "Aspect sentiment classification (ASC) is a fundamental task in sentiment analysis. Given an aspect/target and a sentence, the task classifies the sentiment polarity expressed on the target in the sentence. Memory networks (MNs) have been used for this task recently and have achieved state-of-the-art results. In MNs, attention mechanism plays a crucial role in detecting the sentiment context for the given target. However, we found an important problem with the current MNs in performing the ASC task. Simply improving the attention mechanism will not solve it. The problem is referred to as target-sensitive sentiment, which means that the sentiment polarity of the (detected) context is dependent on the given target and it cannot be inferred from the context alone. To tackle this problem, we propose the target-sensitive memory networks (TMNs). Several alternative techniques are designed for the implementation of TMNs and their effectiveness is experimentally evaluated.",
}

@inproceedings{bohnet-etal-2018-morphosyntactic,
	title = "Morphosyntactic Tagging with a Meta-{B}i{LSTM} Model over Context Sensitive Token Encodings",
	author = "Bohnet, Bernd  and
	McDonald, Ryan  and
	Sim{\~o}es, Gon{\c{c}}alo  and
	Andor, Daniel  and
	Pitler, Emily  and
	Maynez, Joshua",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/P18-1246",
	pages = "2642--2652",
	abstract = "The rise of neural networks, and particularly recurrent neural networks, has produced significant advances in part-of-speech tagging accuracy. One characteristic common among these models is the presence of rich initial word encodings. These encodings typically are composed of a recurrent character-based representation with dynamically and pre-trained word embeddings. However, these encodings do not consider a context wider than a single word and it is only through subsequent recurrent layers that word or sub-word information interacts. In this paper, we investigate models that use recurrent neural networks with sentence-level context for initial character and word-based representations. In particular we show that optimal results are obtained by integrating these context sensitive representations through synchronized training with a meta-model that learns to combine their states.",
}

@inproceedings{huang-carley-2018-parameterized,
	title = "Parameterized Convolutional Neural Networks for Aspect Level Sentiment Classification",
	author = "Huang, Binxuan  and
	Carley, Kathleen",
	booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
	month = oct # "-" # nov,
	year = "2018",
	address = "Brussels, Belgium",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D18-1136",
	pages = "1091--1096",
	abstract = "We introduce a novel parameterized convolutional neural network for aspect level sentiment classification. Using parameterized filters and parameterized gates, we incorporate aspect information into convolutional neural networks (CNN). Experiments demonstrate that our parameterized filters and parameterized gates effectively capture the aspect-specific features, and our CNN-based models achieve excellent results on SemEval 2014 datasets.",
}

@inproceedings{pang-etal-2002-thumbs,
	title = "Thumbs up? Sentiment Classification using Machine Learning Techniques",
	author = "Pang, Bo  and
	Lee, Lillian  and
	Vaithyanathan, Shivakumar",
	booktitle = "Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing",
	month = jul,
	year = "2002",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/W02-1011",
	doi = "10.3115/1118693.1118704",
	pages = "79--86",
}


@inproceedings{kim-2014-convolutional,
	title = "Convolutional Neural Networks for Sentence Classification",
	author = "Kim, Yoon",
	booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
	month = oct,
	year = "2014",
	address = "Doha, Qatar",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/D14-1181",
	doi = "10.3115/v1/D14-1181",
	pages = "1746--1751",
}

@INPROCEEDINGS{CNN, 
author={X. {Ouyang} and P. {Zhou} and C. H. {Li} and L. {Liu}}, 
booktitle={2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing}, 
title={Sentiment Analysis Using Convolutional Neural Network}, 
year={2015}, 
volume={}, 
number={}, 
pages={2359-2364}, 
keywords={learning (artificial intelligence);neural net architecture;sentiment analysis;text content sentiment analysis;convolutional neural network;natural language processing tasks;social media;Big Data;Internet;deep learning models;Word2vec framework;word vector representation;CNN architecture;pooling layers;convolutional layers;7-layers architecture model;sentence sentiment analysis;parametric rectified linear unit;PReLU;normalization and dropout technology;recursive neural network;RNN;matrix-vector recursive neural network;MV-RNN;Neural networks;Sentiment analysis;Machine learning;Google;Analytical models;Media;Computational modeling;sentiment analysis;deep learning;word2vec}, 
doi={10.1109/CIT/IUCC/DASC/PICOM.2015.349}, 
ISSN={}, 
month={Oct},}

@article{Hochreiter:1997:LSM:1246443.1246450,
	author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
	title = {Long Short-Term Memory},
	journal = {Neural Comput.},
	issue_date = {November 15, 1997},
	volume = {9},
	number = {8},
	month = nov,
	year = {1997},
	issn = {0899-7667},
	pages = {1735--1780},
	numpages = {46},
	url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	acmid = {1246450},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
} 

@article{Schuster:1997:BRN:2198065.2205129,
	author = {Schuster, M. and Paliwal, K.K.},
	title = {Bidirectional Recurrent Neural Networks},
	journal = {Trans. Sig. Proc.},
	issue_date = {November 1997},
	volume = {45},
	number = {11},
	month = nov,
	year = {1997},
	issn = {1053-587X},
	pages = {2673--2681},
	numpages = {9},
	url = {http://dx.doi.org/10.1109/78.650093},
	doi = {10.1109/78.650093},
	acmid = {2205129},
	publisher = {IEEE Press},
	address = {Piscataway, NJ, USA},
} 

@article{Go_Bhayani_Huang_2009,
	author = {Go, Alec and Bhayani, Richa and Huang, Lei},
	journal = {Processing},
	keywords = {2011 analysis semantic seminar talk twitter winter},
	pages = {1--6},
	title = {Twitter Sentiment Classification using Distant Supervision},
	url = {http://www.stanford.edu/~alecmgo/papers/TwitterDistantSupervision09.pdf},
	year = 2009
}


@misc{word2vec,
	title	= {Efficient Estimation of Word Representations in Vector Space},
	author	= {Tomas Mikolov and Kai Chen and Greg S. Corrado and Jeffrey Dean},
	year	= {2013},
	URL	= {http://arxiv.org/abs/1301.3781}
}
@misc{dataset:RT,
	author={{Kaggle}},
	title = {Sentiment Analysis on Movie Reviews},
	year = {2015},
	note = {data retrieved from Kaggle, 
	\url{https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews}}
}

@misc{dataset:TW,
	author={Alec Go},
	title = {Sentiment140},
	year = {2009},
	note = {data provided by \citet{Go_Bhayani_Huang_2009}},
	url = {http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip}
}

@misc{report:repo,
	author={Daniyar Kultayev and Kamalkhan Artykbayev},
	title = {Sentiment Analysis Report},
	year = {2019},
	note = {report drive repository for all elements},
	url = {https://drive.google.com/drive/folders/1V8fLDlbyIJ6atqQyZT153QA9AeGWyT_C}
}


